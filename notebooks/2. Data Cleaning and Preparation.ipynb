{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "intensive-sleeve",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import shapely\n",
    "from shapely import wkt\n",
    "import h3\n",
    "from datetime import date\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "#from fastparquet import write\n",
    "#from parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contemporary-appearance",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "massive-reputation",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/df_sample_27_06_2021.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-189db4cb187a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/df_sample_27_06_2021.parquet\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"PU_Centroid\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoints_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Pickup Centroid Longitude\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Pickup Centroid Latitude\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"DO_Centroid\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoints_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dropoff Centroid Longitude\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dropoff Centroid Latitude\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#df = df.drop(columns = [\"Pickup Centroid Latitude\",\"Pickup Centroid Longitude\",\"Dropoff Centroid Latitude\",\"Dropoff Centroid Longitude\"])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Trip Start Timestamp\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Trip Start Timestamp\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mformat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'%m/%d/%Y %I:%M:%S %p'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, use_nullable_dtypes, **kwargs)\u001b[0m\n\u001b[1;32m    458\u001b[0m     \u001b[0mimpl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     return impl.read(\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_nullable_dtypes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_nullable_dtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m     )\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, path, columns, use_nullable_dtypes, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"filesystem\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m             \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m         )\n\u001b[1;32m    220\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36m_get_path_or_handle\u001b[0;34m(path, fs, storage_options, mode, is_dir)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;31m# fsspec resources can also point to directories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;31m# this branch is used for example when reading from non-fsspec URLs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mhandles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0mfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mpath_or_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 656\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    657\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/df_sample_27_06_2021.parquet'"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet(\"../data/df_sample_21_06_2021.parquet\")\n",
    "df[\"PU_Centroid\"] = gpd.points_from_xy(df[\"Pickup Centroid Longitude\"], df[\"Pickup Centroid Latitude\"])\n",
    "df[\"DO_Centroid\"] = gpd.points_from_xy(df[\"Dropoff Centroid Longitude\"], df[\"Dropoff Centroid Latitude\"])                                                   \n",
    "df = df.drop(columns = [\"Pickup Centroid Location\",\"Dropoff Centroid  Location\"])\n",
    "df[\"Trip Start Timestamp\"] = pd.to_datetime(df[\"Trip Start Timestamp\"],format = '%m/%d/%Y %I:%M:%S %p')\n",
    "df[\"Trip End Timestamp\"] = pd.to_datetime(df[\"Trip End Timestamp\"],format = '%m/%d/%Y %I:%M:%S %p')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apparent-possible",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Trip Seconds'].notna()]\n",
    "df = df[df['Trip Miles'].notna()]\n",
    "df = df[df['Trip Total'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handy-frequency",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df.nsmallest(int(df.index.size * 0.999), \"Trip Total\", keep='first')\n",
    "total_filter = df_filtered[\"Trip Total\"].max()\n",
    "min_total = df_filtered[\"Trip Total\"].min()\n",
    "print(\"Max Total:\",total_filter)\n",
    "print(\"Min Total:\",min_total)\n",
    "\n",
    "df_filtered = df.nsmallest(int(df.index.size * 0.999), \"Trip Seconds\", keep='first')\n",
    "seconds_filter = df_filtered[\"Trip Seconds\"].max()\n",
    "min_seconds = df_filtered[\"Trip Seconds\"].min()\n",
    "print(\"Max Seconds:\",seconds_filter)\n",
    "print(\"Min Seconds:\",min_seconds)\n",
    "\n",
    "df = df.copy()[(df[\"Trip Total\"] <= total_filter)&\n",
    "                   (df[\"Trip Seconds\"]<=seconds_filter)&\n",
    "                   (df[\"Trip Seconds\"]> 60)]\n",
    "print(\"Kept\",np.round(df.index.size / df.index.size,4),\"percent of data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dependent-exhaust",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kick out values under 2$\n",
    "print(\"0$ Total Trips:\",df[df[\"Trip Total\"]==0].index.size)\n",
    "print(\"0$ Fare Trips:\",df[df[\"Fare\"]==0].index.size)\n",
    "\n",
    "\n",
    "df = df.copy()[(df[\"Trip Total\"] >= 2)&\n",
    "                   (df[\"Fare\"]>=2)]\n",
    "\n",
    "print(\"New min Total: \",min(df[\"Trip Total\"]))\n",
    "print(\"New max Total: \",max(df[\"Trip Total\"]))\n",
    "print(\"New min Fare: \",min(df[\"Fare\"]))\n",
    "print(\"New max Fare: \",max(df[\"Fare\"]))\n",
    "\n",
    "print(\"Kept\",np.round(df.index.size / df.index.size,4),\"percent of data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breathing-scanner",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"New min Total: \",min(df[\"Trip Total\"]))\n",
    "print(\"New max Total: \",max(df[\"Trip Total\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intensive-brass",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For understanding \n",
    "df[[\"Trip Total\",\"Tolls\",\"Tips\",\"Extras\",\"Fare\"]].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessible-nevada",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kick out all values of December and 2018\n",
    "df['start_month'] = df['Trip Start Timestamp'].dt.month\n",
    "df['start_year'] = df['Trip Start Timestamp'].dt.year\n",
    "df['end_month'] = df['Trip End Timestamp'].dt.month\n",
    "df['end_year'] = df['Trip End Timestamp'].dt.year\n",
    "\n",
    "df = df[(df['start_year'] == 2017 ) & (df['end_year'] == 2017) ]\n",
    "df = df[(df['start_month'] !=12 ) & (df['end_month'] !=12) ]\n",
    "print(\"Kept\",np.round(df.index.size / df.index.size,4),\"percent of data\")\n",
    "\n",
    "#Drop columns again\n",
    "df.drop(columns=['start_month', 'start_year', 'end_month' , 'end_year'], inplace = True)\n",
    "\n",
    "print()\n",
    "#Min and Max Trip Start and end\n",
    "print(\"New min start: \",min(df['Trip Start Timestamp']))\n",
    "print(\"New min end: \",min(df['Trip End Timestamp']))\n",
    "print(\"New min start: \",max(df['Trip Start Timestamp']))\n",
    "print(\"New min end: \",max(df['Trip End Timestamp']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunset-impression",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check null values in payment type and company\n",
    "pay_verifier = df['Payment Type'].dropna()\n",
    "print(\"Number of null values within column payment type: \",len(df)-len(pay_verifier))\n",
    "\n",
    "com_verifier = df['Company'].dropna()\n",
    "print(\"Number of null values within column payment type: \",len(df)-len(com_verifier))\n",
    "print()\n",
    "print(\"if 0, we don't have to drop something.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "violent-provider",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Miles have to be checked with the geo data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "freelance-customer",
   "metadata": {},
   "source": [
    "# H3 Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ambient-national",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting Geo-Points to H3\n",
    "\n",
    "def h3_conversion(value,h3_level):\n",
    "    if isinstance(value,shapely.geometry.point.Point):\n",
    "        return h3.geo_to_h3(value.y, value.x, h3_level)\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "df[\"PU_H3\"] = df.apply(lambda x: h3_conversion(x[\"PU_Centroid\"],8),axis=1)\n",
    "df[\"DO_H3\"] = df.apply(lambda x: h3_conversion(x[\"DO_Centroid\"],8),axis=1)\n",
    "df[\"PU_H3\"] = df[\"PU_H3\"].replace(\"0\",np.nan)\n",
    "df[\"DO_H3\"] = df[\"DO_H3\"].replace(\"0\",np.nan)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operating-assault",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "different-civilization",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addDateCols(added_word, used_datetime,df_name): \n",
    "\n",
    "    #added word: Put your indivuword word to the string \n",
    "\n",
    "    #Month and weekday name\n",
    "    df_name[added_word+'_MONTH_NAME'] = df_name[used_datetime].dt.month_name()\n",
    "    df_name[added_word+'_WEEKDAY_NAME'] = df_name[used_datetime].dt.day_name()\n",
    "    \n",
    "    \n",
    "    #Date\n",
    "    df_name[added_word+\"_DATE\"] = df_name[used_datetime].dt.date\n",
    "    #Year\n",
    "    #df_name[added_word+'_YEAR'] = df_name[used_datetime].dt.year\n",
    "    #df_name[added_word+'_YEAR'] = df_name[added_word+'_YEAR'].astype(str)\n",
    "\n",
    "    #Month numeric\n",
    "    df_name[added_word+'_MONTH'] = df_name[used_datetime].dt.month\n",
    "    df_name[added_word+'_MONTH'] = pd.to_numeric(df_name[added_word+'_MONTH'])\n",
    "    \n",
    "    #Weekday numeric\n",
    "    df_name[added_word+'_WEEKDAY'] = df_name[used_datetime].dt.dayofweek\n",
    "    df_name[added_word+'_WEEKDAY'] = pd.to_numeric(df_name[added_word+'_WEEKDAY'])\n",
    "\n",
    "    #Day numeric\n",
    "    df_name[added_word+'_HOUR'] = df_name[used_datetime].dt.hour\n",
    "    df_name[added_word+'_HOUR'] = pd.to_numeric(df_name[added_word+'_HOUR'])+1\n",
    "    \n",
    "    #Day of week\n",
    "    #df_name[added_word+'_HOUR_OF_WEEK'] = (df_name[added_word+'_WEEKDAY']*24) + df_name[added_word+'_HOUR']\n",
    "    \n",
    "    return df_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weekly-memorabilia",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding datetime columns\n",
    "df_prepared = addDateCols(\"PU\",\"Trip Start Timestamp\",df)\n",
    "df_prepared = addDateCols(\"DO\",\"Trip Start Timestamp\",df_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "union-portuguese",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_prepared.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noble-stress",
   "metadata": {},
   "source": [
    "## Option 1: Parrow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "armed-verse",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write parquet of cleaned frame\n",
    "df_compatible = df_prepared.drop(columns=[\"PU_Centroid\",\"DO_Centroid\"])\n",
    "frame = pa.Table.from_pandas(df_compatible)\n",
    "pq.write_table(frame, '../data/df_cleaned_{}.parquet'.format(date.today().strftime(\"%d_%m_%Y\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "timely-occasions",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interested-pierre",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
